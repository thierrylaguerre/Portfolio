# PrÃ©diction des Prix de lâ€™Immobilier  

## Objectif du Projet  
L'objectif de ce projet est de **prÃ©dire les prix de lâ€™immobilier** en fonction de plusieurs caractÃ©ristiques (superficie, nombre de chambres, localisation, etc.). Cette prÃ©diction permet aux acheteurs, vendeurs et investisseurs dâ€™avoir une meilleure estimation des prix du marchÃ©.

## MÃ©thodologie  

1. **Analyse Exploratoire des DonnÃ©es (EDA)**  
   - Ã‰tude des tendances du marchÃ© immobilier.  
   - Visualisation des distributions des prix.  
   - Analyse de la corrÃ©lation entre les variables (superficie, localisation, etc.).  

2. **PrÃ©traitement des DonnÃ©es**  
   - Suppression des **doublons et des valeurs manquantes**.  
   - Encodage des **variables catÃ©gorielles** (localisation, type de logement, etc.).  
   - **Normalisation et standardisation** des donnÃ©es.  
   - SÃ©paration des donnÃ©es en **train/test**.  

3. **ModÃ©lisation & EntraÃ®nement des ModÃ¨les**  
   - **RÃ©gression LinÃ©aire**  
   - **Lasso & Ridge Regression**  
   - **Random Forest Regressor**  
   - **XGBoost**  
   - **CatBoost**  

4. **Ã‰valuation des ModÃ¨les**  
   - **MÃ©triques utilisÃ©es** :  
     - Mean Absolute Error (MAE)  
     - Mean Squared Error (MSE)  
     - RÂ² Score  

## ğŸ“‚ Structure du Projet  

````
projet_6_prediction_immobilier/
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ real_estate_dataset.csv # Dataset des transactions immobiliÃ¨res
â”‚â”€â”€ prediction_immobilier.ipynb # Notebook dâ€™analyse et de modÃ©lisation
â”‚â”€â”€ README.md # PrÃ©sentation gÃ©nÃ©rale du projet
````

## ğŸš€ RÃ©sultats et Analyse  

### Comparaison des ModÃ¨les  

- **RÃ©gression LinÃ©aire & LASSO (97.09% de prÃ©cision)** : Excellentes performances avec un **RÂ² de 0.97** et une **prÃ©cision proche de 97%**. Ces modÃ¨les sont adaptÃ©s pour des prÃ©dictions prÃ©cises et simples.
- **Ridge (97.06% de prÃ©cision)** : TrÃ¨s proche de la rÃ©gression linÃ©aire et du LASSO, offrant des performances similaires mais avec une rÃ©gularisation lÃ©gÃ¨rement diffÃ©rente.
- **CatBoost (91.94% de prÃ©cision)** : Bon modÃ¨le avec une **prÃ©cision de 91.94%**, mais le RÂ² est plus bas (0.92), indiquant qu'il peut y avoir des zones dâ€™amÃ©lioration.
- **XGBoost (84.43% de prÃ©cision)** : Moins performant que CatBoost, mais tout de mÃªme solide avec un **RÂ² de 0.84**. Un peu plus complexe Ã  optimiser mais utile pour des ensembles de donnÃ©es plus complexes.
- **Random Forest (82.44%)** : PrÃ©cision encore plus faible avec un **RÂ² de 0.82**, indiquant que les prÃ©dictions ne sont pas aussi fines que celles des modÃ¨les prÃ©cÃ©dents.
- **K-NN (69.91% de prÃ©cision)** : Le moins performant avec une **prÃ©cision de 69.91%** et un **RÂ² de 0.70**, suggÃ©rant que les voisins peuvent ne pas Ãªtre une bonne approche pour cette tÃ¢che. 

---
