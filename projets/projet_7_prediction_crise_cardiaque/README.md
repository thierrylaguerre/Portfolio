# Projet 7 : Pr√©diction de crise cardiaque

## Description du projet

Ce projet vise √† pr√©dire la probabilit√© de survenue d'une crise cardiaque en fonction de plusieurs facteurs de risque. L'objectif est de construire un mod√®le de classification capable d'identifier les patients √† risque √©lev√© de crise cardiaque. Pour cela, nous utilisons des techniques d'analyse de donn√©es et des mod√®les de machine learning.

## Objectifs

- **√âtudier les facteurs de risque** associ√©s √† la crise cardiaque.
- **Construire un mod√®le pr√©dictif** capable d'estimer la probabilit√© qu'un patient fasse une crise cardiaque.
- **√âvaluer les performances du mod√®le** en termes de pr√©cision et l'AUC-ROC.

## Structure du projet

````
projet_7_prediction_crise_cardiaque/
‚îÇ‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ heart_attack_prediction_dataset.csv.zip # Dataset utilis√© pour la pr√©diction
‚îÇ‚îÄ‚îÄ README.md # Documentation du projet
‚îÇ‚îÄ‚îÄ prediction_crise_cardiaque.ipynb # Notebook contenant l'impl√©mentation du mod√®le
````

## Donn√©es

Le jeu de donn√©es utilis√© dans ce projet contient des informations sur plusieurs variables li√©es √† la sant√© des patients, telles que :

- √Çge
- Sexe
- Taux de cholest√©rol
- Niveau de sucre sanguin
- Pression art√©rielle
- Historique familial de crise cardiaque, etc.

Les donn√©es sont fournies sous forme de fichier CSV compress√© dans le r√©pertoire `data/`.

## üîß M√©thodologie

1. **Pr√©traitement des donn√©es** :
   - Nettoyage des donn√©es (suppression des valeurs manquantes, gestion des valeurs aberrantes).
   - Encodage des variables cat√©gorielles (par exemple, le sexe).
   - Normalisation des donn√©es (scaling des variables num√©riques).

2. **S√©lection des caract√©ristiques** :
   - Identification des principales variables influen√ßant la pr√©diction de crise cardiaque.

3. **Mod√®les de Machine Learning** :
   - **R√©gression logistique** : Un mod√®le lin√©aire simple pour la classification binaire.
   - **Arbre de d√©cision** : Un mod√®le non lin√©aire permettant une interpr√©tation plus facile.
   - **Random Forest** : Un ensemble d'arbres de d√©cision pour am√©liorer la robustesse du mod√®le.
   - **SVM (Support Vector Machine)** : Un mod√®le puissant pour la classification avec marges maximales.
   - **KNN (K-Nearest Neighbors)** : Un mod√®le de classification bas√© sur la proximit√© des points.
   - **Naive Bayes** : Un mod√®le probabiliste bas√© sur le th√©or√®me de Bayes.
   - **Perceptron** : Un mod√®le lin√©aire simple inspir√© des neurones biologiques.

4. **√âvaluation du mod√®le** :
   - √âvaluation de la performance des mod√®les √† l'aide des m√©triques suivantes : 
     - **Pr√©cision**
     - **AUC-ROC**

5. **Analyse et comparaison des performances des mod√®les** :
   - **Random Forest (63,6% de pr√©csion)** : Meilleur mod√®le en termes de pr√©cision, mais l'AUC-ROC est faible, indiquant une capacit√© limit√©e √† distinguer les classes.
   - **Decision Tree (54,5% de pr√©cision)**: Moins performant que Random Forest, avec une pr√©cision plus faible et un AUC-ROC √©galement faible.
   - **Gaussian Naive Bayes (64,2% de pr√©cision)** : Bonne pr√©cision, mais l'AUC-ROC reste faible, ce qui signifie qu'il n'est pas tr√®s efficace pour classer les classes de mani√®re discr√®te.
   - **Logistic Regression (64,2% de pr√©cision)** : Tr√®s similaire √† Gaussian Naive Bayes en termes de pr√©cision et AUC-ROC, avec une bonne pr√©cision mais une faible capacit√© √† s√©parer les classes.
   - **K-Nearest Neighbors (57,2% de pr√©cision)** : Pr√©cision plus faible et AUC-ROC √©galement limit√©. Pas tr√®s performant sur cette t√¢che.
   - **Multi-Layer Perceptron (MLP) (56,2% de pr√©cision)** : Similaire √† KNN et Decision Tree, avec une faible performance en termes de s√©paration des classes.
   - **SVM (0.642, AUC-ROC: 0.461)** : Pr√©cision correcte, mais l'AUC-ROC est faible, ce qui sugg√®re que le mod√®le ne capture pas bien les diff√©rentes classes.

